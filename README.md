# DeepLearning
This is a complete Deep learning topics that can help you find out what is out there in this field.

<H1>Supervised Learning</H1>
<table>
<tr>
  <th>Topic</th>
  <th>Explaination</th>
  <th>Example</th>
</tr>
<tr>
    <td>Feedforward Neural Networks (FNNs)</td>
  </tr>
  <tr>
    <td>Convolutional Neural Networks (CNNs)</td>
  </tr>
  <tr>
    <td>Recurrent Neural Networks (RNNs)</td>
  </tr>
  <tr>
    <td>Long Short-Term Memory (LSTM)</td>
  </tr>
  <tr>
    <td>Gated Recurrent Units (GRUs)</td>
  </tr>
  <tr>
    <td>Autoencoders</td>
  </tr>  
  <tr>
    <td>Variational Autoencoders (VAEs)</td>
  </tr>
  <tr>
    <td>Generative Adversarial Networks (GANs)</td>
  </tr>
  <tr>
    <td>Siamese Networks</td>
  </tr>
  <tr>
    <td>Transfer Learning</td>
  </tr>


 
  <tr>
        <td>Neural Architecture Search (NAS)</td>
        <td>Automated process of finding optimal neural network architectures.</td>
    </tr>
    <tr>
        <td>Meta-Learning</td>
        <td>Learning to learn; algorithms that improve learning efficiency and adaptation.</td>
    </tr>
    <tr>
        <td>One-shot Learning</td>
        <td>Learning a task from only a single example or very few examples.</td>
    </tr>
    <tr>
        <td>Few-shot Learning</td>
        <td>Learning a task from a few examples or data points.</td>
    </tr>
    <tr>
        <td>Zero-shot Learning</td>
        <td>Learning to recognize new concepts without labeled training examples.</td>
    </tr>

  
</table>


<H1>Unsupervised Learning</H1>
<table>
<tr>
  <th>Topic</th>
  <th>Example</th>
</tr>
    <tr>
    <td>Principal Component Analysis (PCA)</td>
  </tr>
  <tr>
    <td>t-Distributed Stochastic Neighbor Embedding (t-SNE)</td>
  </tr>
  <tr>
    <td>Uniform Manifold Approximation and Projection (UMAP)</td>
  </tr>
</table>

<H1>Self-Supervised Learning</H1>

<table>
<tr>
  <th>Topic</th>
  <th>Example</th>
</tr>

  <tr>
    <td>Autoencoders</td>
  </tr>
  <tr>
    <td>Generative Adversarial Networks (GANs)</td>
  </tr>
  <tr>
    <td>Contrastive Learning</td>
  </tr>
  <tr>
    <td>Predictive Coding</td>
  </tr>
  <tr>
    <td>Clustering</td>
  </tr>
  <tr>
    <td>Self-supervised Pretraining</td>
  </tr>

 
  
</table>

<H1>Reinfocement Learning</H1>
<table>
<tr>
  <th>Topic</th>
  <th>Explaination</th>
  <th>Example</th>
</tr>
  <tr>
        <td>Proximal Policy Optimization (PPO)</td>
        <td>An on-policy RL algorithm that uses a clipped objective function to reduce variance and improve stability.</td>
    </tr>
    <tr>
        <td>Soft Actor-Critic (SAC)</td>
        <td>An off-policy RL algorithm that combines policy gradient methods and Q-learning with entropy regularization.</td>
    </tr>
    <tr>
        <td>Twin Delayed DDPG (TD3)</td>
        <td>An off-policy RL algorithm that addresses function approximation errors in DDPG using two Q-functions and a delay for policy updates.</td>
    </tr>
    <tr>
        <td>Deep Q-Networks (DQN)</td>
        <td>A value-based RL algorithm that uses a deep neural network to approximate the action-value function for discrete action spaces.</td>
    </tr>
    <tr>
        <td>Rainbow</td>
        <td>An extension of DQN that combines several improvements, such as prioritized experience replay, multi-step learning, and distributional RL.</td>
    </tr>
    <tr>
        <td>Advantage Actor-Critic (A2C/A3C)</td>
        <td>On-policy RL algorithms that use multiple parallel agents to learn a policy and a value function simultaneously for continuous action spaces.</td>
    </tr>
    <tr>
        <td>Trust Region Policy Optimization (TRPO)</td>
        <td>An on-policy RL algorithm that uses a trust region optimization method to update the policy parameters for continuous action spaces.</td>
    </tr>
    <tr>
        <td>Meta-Reinforcement Learning (Meta-RL)</td>
        <td>A family of RL algorithms that learn a meta-policy that can quickly adapt to new tasks with a few gradient updates.</td>
    </tr>
    <tr>
        <td>Curiosity-driven Exploration</td>
        <td>A technique that encourages agents to explore novel states by rewarding them for visiting states with high prediction error.</td>
    </tr>
    <tr>
        <td>Hindsight Experience Replay (HER)</td>
        <td>An off-policy RL algorithm that addresses the sparse reward problem by relabeling trajectories with virtual rewards.</td>
    </tr>
</table>
  
<H1>Uncategorized</H1>
<table>
<tr>
  <th>Topic</th>
  <th>Explaination</th>
  <th>Example</th>
</tr>
      <tr>
        <td>Explainable AI (XAI)</td>
        <td>AI systems that can explain their decision-making processes in a human-understandable way.</td>
    </tr>
    <tr>
        <td>Adversarial Attacks and Defenses</td>
        <td>Techniques for attacking and defending against adversarial inputs in machine learning models.</td>
    </tr>
    <tr>
        <td>Federated Learning</td>
        <td>Decentralized machine learning approach where multiple devices collaboratively train a model while keeping data local.</td>
    </tr>
    <tr>
        <td>Graph Neural Networks (GNNs)</td>
        <td>Neural networks designed to operate on graph-structured data, capturing relational information.</td>
    </tr>
 <tr>
        <td>Deep Stacking Networks (DSNs)</td>
        <td>Hierarchical deep learning models that stack multiple layers of abstraction.</td>
    </tr>
    <tr>
        <td>Capsule Networks (CapsNets)</td>
        <td>Neural network architecture designed to better understand hierarchical relationships in data.</td>
    </tr>
    <tr>
        <td>Neural Turing Machines (NTMs)</td>
        <td>Neural network models augmented with external memory for more complex computations.</td>
    </tr>
    <tr>
        <td>Differentiable Programming</td>
        <td>Using differentiable structures to enable learning and optimization within non-standard computing environments.</td>
    </tr>
</table>

<small> Descriptions are created by misteral.ai and chatgpt. </small>
